#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import sqlite3
import sys
import tempfile
import time
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))


def _percentile(samples: list[float], q: float) -> float:
    if not samples:
        return 0.0
    ordered = sorted(samples)
    idx = max(0, min(len(ordered) - 1, int(round(q * (len(ordered) - 1)))))
    return float(ordered[idx])


def _ensure_events_table(db_path: Path) -> None:
    con = sqlite3.connect(str(db_path))
    try:
        con.execute(
            """
            CREATE TABLE IF NOT EXISTS events(
              id INTEGER PRIMARY KEY AUTOINCREMENT,
              ts TEXT NOT NULL,
              event_type TEXT NOT NULL,
              entity_type TEXT NOT NULL,
              entity_id INTEGER NOT NULL,
              payload_json TEXT NOT NULL,
              prev_hash TEXT NOT NULL,
              hash TEXT NOT NULL UNIQUE
            )
            """
        )
        con.commit()
    finally:
        con.close()


def run_benchmark(events: int) -> dict[str, float | int]:
    from app.automation.runner import simulate_rule_for_tenant
    from app.automation.store import create_rule, ensure_automation_schema
    from app.eventlog.core import event_append

    tenant = "KUKANILEA"
    with tempfile.TemporaryDirectory(prefix="kukanilea_bench_workflows_") as tmp:
        db_path = Path(tmp) / "core.sqlite3"
        ensure_automation_schema(db_path)
        _ensure_events_table(db_path)

        rule_id = create_rule(
            tenant_id=tenant,
            name="Bench Rule",
            description="Benchmark simulation rule",
            triggers=[
                {
                    "type": "eventlog",
                    "config": {"allowed_event_types": ["task_moved"]},
                }
            ],
            actions=[
                {
                    "type": "create_task",
                    "config": {
                        "title": "Bench task",
                        "details": "Generated by benchmark",
                    },
                }
            ],
            db_path=db_path,
        )

        con = sqlite3.connect(str(db_path))
        con.row_factory = sqlite3.Row
        event_ids: list[int] = []
        try:
            for idx in range(max(1, int(events))):
                event_id = event_append(
                    event_type="task_moved",
                    entity_type="task",
                    entity_id=idx + 1,
                    payload={"tenant_id": tenant, "task_status": "RESOLVED"},
                    con=con,
                )
                event_ids.append(int(event_id))
            con.commit()
        finally:
            con.close()

        latencies_ms: list[float] = []
        ok_count = 0
        error_count = 0
        for event_id in event_ids:
            started = time.perf_counter()
            result = simulate_rule_for_tenant(
                tenant,
                rule_id,
                db_path=db_path,
                event_id=event_id,
            )
            elapsed_ms = (time.perf_counter() - started) * 1000.0
            latencies_ms.append(elapsed_ms)
            if bool(result.get("ok")):
                ok_count += 1
            else:
                error_count += 1

        total_ms = float(sum(latencies_ms))
        return {
            "events": len(event_ids),
            "ok_count": ok_count,
            "error_count": error_count,
            "total_ms": round(total_ms, 3),
            "p50_ms": round(_percentile(latencies_ms, 0.50), 3),
            "p95_ms": round(_percentile(latencies_ms, 0.95), 3),
            "p99_ms": round(_percentile(latencies_ms, 0.99), 3),
            "avg_ms": round(total_ms / max(1, len(latencies_ms)), 3),
        }


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Benchmark workflow simulation throughput over synthetic events."
    )
    parser.add_argument("--events", type=int, default=100)
    parser.add_argument("--json-out", type=str, default="")
    args = parser.parse_args()

    report = run_benchmark(events=args.events)
    text = json.dumps(report, ensure_ascii=False, indent=2)
    print(text)
    if args.json_out:
        with open(args.json_out, "w", encoding="utf-8") as fh:
            fh.write(text + "\n")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
